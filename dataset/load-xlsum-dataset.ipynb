{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcf7d9d",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc04068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library untuk load dataset dadri Hugging Face\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_config_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8dc2f0",
   "metadata": {},
   "source": [
    "# Load Dataset XL-Sum dari Platform Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb61071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: Dataset({\n",
      "    features: ['id', 'url', 'title', 'summary', 'text'],\n",
      "    num_rows: 38242\n",
      "}) \n",
      "\n",
      "Test SET: Dataset({\n",
      "    features: ['id', 'url', 'title', 'summary', 'text'],\n",
      "    num_rows: 4780\n",
      "}) \n",
      "\n",
      "VALIDATION SET: Dataset({\n",
      "    features: ['id', 'url', 'title', 'summary', 'text'],\n",
      "    num_rows: 4780\n",
      "}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset XL-Sum terdiri dari banyak bahasa (multilingual language), pada project ini akan mengambil dataset XL-Sum bahasa Indonesia\n",
    "train_dataset = load_dataset(\"csebuetnlp/xlsum\", name=\"indonesian\", split=\"train\")\n",
    "test_dataset = load_dataset(\"csebuetnlp/xlsum\", name=\"indonesian\", split=\"test\")\n",
    "val_dataset = load_dataset(\"csebuetnlp/xlsum\", name=\"indonesian\", split=\"validation\")\n",
    "\n",
    "print(f\"TRAIN SET: {train_dataset} \\n\")\n",
    "print(f\"Test SET: {test_dataset} \\n\")\n",
    "print(f\"VALIDATION SET: {val_dataset} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b980327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data XLSUM Bahasa Indonesia: 47802\n",
      "Train Data: 38242\n",
      "Test Data: 4780\n",
      "Validation Data: 4780\n"
     ]
    }
   ],
   "source": [
    "# Convert ke Pandas DataFrame untuk proses lebih lanjut\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "val_df = pd.DataFrame(val_dataset)\n",
    "\n",
    "# Detail Dataset XL-Sum Bahasa Indonesia\n",
    "total = len(train_df) + len(test_df) + len(val_df)\n",
    "\n",
    "print(f\"Total Data XLSUM Bahasa Indonesia: {total}\")\n",
    "print(f\"Train Data: {len(train_df)}\")\n",
    "print(f\"Test Data: {len(test_df)}\")\n",
    "print(f\"Validation Data: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c42496",
   "metadata": {},
   "source": [
    "# Clean Dataset\n",
    "##### Setelah tahap load dataset, selanjutnya dataset XL-Sum akan dilakukan tahap cleaning data (cek null values, cek duplikasi, dan hapus kolom yang tidak digunakan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bc9e7",
   "metadata": {},
   "source": [
    "## Cek Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c6309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset null values:\n",
      "id         0\n",
      "url        0\n",
      "title      0\n",
      "summary    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n",
      "Test dataset null values:\n",
      "id         0\n",
      "url        0\n",
      "title      0\n",
      "summary    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n",
      "Validation dataset null values:\n",
      "id         0\n",
      "url        0\n",
      "title      0\n",
      "summary    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek null values\n",
    "print(\"Train dataset null values:\")\n",
    "print(f\"{train_df.isnull().sum()}\\n\")\n",
    "\n",
    "print(\"Test dataset null values:\")\n",
    "print(f\"{test_df.isnull().sum()}\\n\")\n",
    "\n",
    "print(\"Validation dataset null values:\")\n",
    "print(f\"{val_df.isnull().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f5bcd",
   "metadata": {},
   "source": [
    "## Cek Duplikasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a7556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset duplicate values: 0\n",
      "\n",
      "Test dataset duplicate values: 0\n",
      "\n",
      "Validation dataset duplicate values: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek data duplikat\n",
    "print(f\"Train dataset duplicate values: {train_df.duplicated().sum()}\\n\")\n",
    "\n",
    "print(f\"Test dataset duplicate values: {test_df.duplicated().sum()}\\n\")\n",
    "\n",
    "print(f\"Validation dataset duplicate values: {val_df.duplicated().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7d298",
   "metadata": {},
   "source": [
    "# Hapus kolom yang tidak digunakan\n",
    "##### Dataset pada tugas peringkas teks otomatis hanya membutuhkan dua input yaitu \"text\" dan \"summary\" selain itu akan dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAIL TRAIN DATASET:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38242 entries, 0 to 38241\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   summary  38242 non-null  object\n",
      " 1   text     38242 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 597.7+ KB\n",
      "None\n",
      "\n",
      "DETAIL TEST DATASET:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4780 entries, 0 to 4779\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   summary  4780 non-null   object\n",
      " 1   text     4780 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 74.8+ KB\n",
      "None\n",
      "\n",
      "DETAIL VALIDATION DATASET:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4780 entries, 0 to 4779\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   summary  4780 non-null   object\n",
      " 1   text     4780 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 74.8+ KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(columns=['id', 'url', 'title'])\n",
    "test_df = test_df.drop(columns=['id', 'url', 'title'])\n",
    "val_df = val_df.drop(columns=['id', 'url', 'title'])\n",
    "\n",
    "print(\"DETAIL TRAIN DATASET:\")\n",
    "print(f\"{train_df.info()}\\n\")\n",
    "\n",
    "print(\"DETAIL TEST DATASET:\")\n",
    "print(f\"{test_df.info()}\\n\")\n",
    "\n",
    "print(\"DETAIL VALIDATION DATASET:\")\n",
    "print(f\"{val_df.info()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fa7bb",
   "metadata": {},
   "source": [
    "## Simpan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9f46a",
   "metadata": {},
   "source": [
    "##### Agar semakin robust, seluruh dataset akan digabung dan disimpan dalam format .csv, selanjutnya akan digunakan pada tahap K-fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7720191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan dataset menjadi satu DataFrame\n",
    "combined_df = pd.concat([train_df, test_df, val_df], ignore_index=True)\n",
    "\n",
    "# Simpan DataFrame ke file CSV\n",
    "combined_df.to_csv(\"output/xlsum_indonesia.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
